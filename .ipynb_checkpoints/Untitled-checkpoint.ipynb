{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e6222b-5531-4c59-a9e0-4e2f45c19cb8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce25478-7736-4d85-b25e-34bc17ea8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import re\n",
    "import regex\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Bidirectional, LSTM, GlobalMaxPool1D, Dropout, SpatialDropout1D\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33137ab-e9d5-4ef2-9735-55f8e5614215",
   "metadata": {},
   "source": [
    "read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c53299-4354-4410-a1af-21a93c122895",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/imdb.csv', engine='python')\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba2db8-e07a-447e-84ce-e12978ea8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1., random_state=14).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f6f67-5f74-4c05-bf0a-bdabc7291307",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[data.sentiment == 1].sentiment,\n",
    "         bins=2, color='green', label='Positive')\n",
    "plt.hist(data[data.sentiment == 0].sentiment,\n",
    "         bins=2, color='blue', label='Negative')\n",
    "plt.title('Classes distribution in the train data', fontsize=12)\n",
    "plt.xticks([])\n",
    "plt.xlim(-0.5, 2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f10e09a-4444-421c-8ff7-4f118a7d8aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hammer house of horror witching time is set in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no matter what country your in you have to buy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a really cute movie  inspir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woosh man what can i saythe openingscene maybe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this movie is nothing more than christian prop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  hammer house of horror witching time is set in...          1\n",
       "1  no matter what country your in you have to buy...          1\n",
       "2  i thought this was a really cute movie  inspir...          1\n",
       "3  woosh man what can i saythe openingscene maybe...          0\n",
       "4  this movie is nothing more than christian prop...          0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = regex.sub(r\"<[^<]+?>\", \"\", text)\n",
    "\n",
    "    # Remove Special chars\n",
    "    text = regex.sub(r'[^a-zA-Z0-9\\s]', \"\", text)\n",
    "\n",
    "    # Convet to LowerCase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "data[\"review\"] = data[\"review\"].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3cf7f51-ebbf-436b-9f20-ba4fff93a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40000,)\n",
      "y_train shape: (40000,)\n",
      "X_val shape: (5000,)\n",
      "y_val shape: (5000,)\n",
      "X_test: (5000,)\n",
      "y_test: (5000,)\n"
     ]
    }
   ],
   "source": [
    "X = data['review']\n",
    "y = data['sentiment']\n",
    "X_main, X_test, y_main, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y, shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=0.11111111, random_state=42, stratify=y_main,\n",
    "                                                  shuffle=True)\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))\n",
    "print(\"X_test: {}\".format(X_test.shape))\n",
    "print(\"y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee221855-9fd5-42f0-af9c-d25064686a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192660\n"
     ]
    }
   ],
   "source": [
    "max_length = 200\n",
    "vocab_size = 140631\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c775e80-686d-4b0a-83fd-bf0c4d9b7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = tokenizer.texts_to_sequences(X_train)\n",
    "val_seqs = tokenizer.texts_to_sequences(X_val)\n",
    "test_seqs = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "train_seqs = pad_sequences(train_seqs, padding='post', maxlen=max_length, truncating='post')\n",
    "val_seqs = pad_sequences(val_seqs, padding='post', maxlen=max_length, truncating='post')\n",
    "test_seqs = pad_sequences(test_seqs, padding='post', maxlen=max_length, truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "697a79bc-19ad-45ef-84fd-8909c09c923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         18000768  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 128)        98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,103,745\n",
      "Trainable params: 18,103,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 128, name=\"embedding\"),\n",
    "    Bidirectional(LSTM(64, return_sequences=True, dropout=0.2)),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dropout(0.05),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37aeb42d-24a5-4972-9e54-d5ebf167ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1250/1250 [==============================] - 191s 151ms/step - loss: 0.3543 - accuracy: 0.8397 - val_loss: 0.2699 - val_accuracy: 0.8882\n",
      "Epoch 2/2\n",
      "1250/1250 [==============================] - 193s 155ms/step - loss: 0.1624 - accuracy: 0.9395 - val_loss: 0.2869 - val_accuracy: 0.8916\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_seqs, y_train, epochs=2, validation_data=(val_seqs, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4506fcc7-c5fe-427d-ba00-4afeb1ba76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 5s 25ms/step\n",
      "[0.98 0.   0.01 ... 0.93 0.   0.13]\n",
      "[1 0 0 ... 1 0 0]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      2500\n",
      "           1       0.89      0.89      0.89      2500\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2212  288]\n",
      " [ 271 2229]]\n",
      "Accuracy Score: \n",
      " 0.8882\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "predict_p = model.predict(test_seqs)\n",
    "predict_p = predict_p.flatten()\n",
    "print(predict_p.round(2))\n",
    "\n",
    "# Result\n",
    "pred = np.where(predict_p > 0.5, 1, 0)\n",
    "print(pred)\n",
    "\n",
    "classi = classification_report(y_test, pred)\n",
    "confu = confusion_matrix(y_test, pred)\n",
    "accu = accuracy_score(y_test, pred)\n",
    "\n",
    "# Display the outcome of classification\n",
    "print('Classification Report: \\n', classi)\n",
    "print('Confusion Matrix: \\n', confu)\n",
    "print('Accuracy Score: \\n', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "547a2b73-56c4-4f0e-ba4a-28d3e0d5a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('88.h5')\n",
    "model.save('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8913ce0-dfe2-4ce9-bc46-e24d3a84fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word_num in range(1, vocab_size - 1):\n",
    "    word = reverse_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55296435-9a45-47c2-b5e5-62d83e6ba4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
